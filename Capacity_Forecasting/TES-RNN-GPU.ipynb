{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TES-RNN-GPU.ipynb","provenance":[],"collapsed_sections":["l8Q8pYyRqFQo","h9E0aE5QrdZY","2ypeVqGAuSRZ"]},"kernelspec":{"display_name":"ES-NN","language":"python","name":"es-nn"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"markdown","source":["# ***Installation Requirements***\n","\n"],"metadata":{"id":"l8Q8pYyRqFQo"}},{"cell_type":"code","metadata":{"id":"3Y1czngSveec","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649889210024,"user_tz":-120,"elapsed":3583,"user":{"displayName":"Leonardo Lo Schiavo","userId":"03721989530819158623"}},"outputId":"c28ddab3-d8c1-48f8-95f2-ffdc3242b70f"},"source":["!pip install tensorflow==1.14"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.7/dist-packages (1.14.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.0.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.5.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.44.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.21.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.37.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.1.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n"]}]},{"cell_type":"markdown","source":["# ***Mount Google Drive***"],"metadata":{"id":"h9E0aE5QrdZY"}},{"cell_type":"code","metadata":{"id":"qA4zUfv_vkBp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649889212407,"user_tz":-120,"elapsed":2392,"user":{"displayName":"Leonardo Lo Schiavo","userId":"03721989530819158623"}},"outputId":"5f67d72a-819e-46b6-c35a-c18b06433bb7"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My\\ Drive/TES-RNN-GPU_Github/Capacity_Forecasting"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","/gdrive/My Drive/TES-RNN-GPU_Github/Capacity_Forecasting\n"]}]},{"cell_type":"markdown","source":["# ***Imports***"],"metadata":{"id":"2ypeVqGAuSRZ"}},{"cell_type":"code","metadata":{"id":"4dkRuMNhqwFw","executionInfo":{"status":"ok","timestamp":1649889212407,"user_tz":-120,"elapsed":5,"user":{"displayName":"Leonardo Lo Schiavo","userId":"03721989530819158623"}}},"source":["import math\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from data_loading import create_dataset, Dataset\n","from config import get_config\n","from trainer import TESRNNTrainer\n","from validator import TESRNNValidator\n","from tester import TESRNNTester\n","from model import TESRNN\n","from loss_modules import *"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# ***TES-RNN***"],"metadata":{"id":"mBI-C5mczUjW"}},{"cell_type":"code","metadata":{"id":"4TKcS_0NreF_","executionInfo":{"status":"ok","timestamp":1649889212407,"user_tz":-120,"elapsed":4,"user":{"displayName":"Leonardo Lo Schiavo","userId":"03721989530819158623"}}},"source":["# CONFIGURATION SETTINGS\n","\n","# List of the services to be tested\n","#services = ['Facebook', 'Instagram', 'Snapchat', 'Twitter', 'YouTube']\n","services = ['Facebook']\n","\n","# Number of clusters\n","num_clusters = 1\n","\n","# List of alphas to be tested\n","alphas = [5]\n","\n","# Define the number of training epochs\n","epochs = 1\n","\n","# Define the number of training batch size\n","batch_size = 288\n","\n","# Define the number of train, validation and test samples\n","train_samples = 16128\n","val_samples = 4032\n","test_samples = 2016\n","\n","# Define the input size and output size of the prediction\n","input_size = 6\n","output_size = 1\n","\n","# Golden ratio for the golden search algorithm\n","gratio = (math.sqrt(5) + 1) / 2\n","\n","# Stopping condition value for the golden search algorithm (interval length)\n","stop_value = 0.01"],"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# SIMULATION RUNS\n","num_runs = 1\n","\n","# Simulations over different services\n","for service in services:\n","\n","    # Simulations over different alpha values\n","    for alpha in alphas:\n","\n","        # Configuration loading\n","        config = get_config('Traffic', epochs, num_clusters, batch_size, train_samples, val_samples, test_samples, alpha, input_size, output_size)\n","    \n","        # Data loading\n","        data = '../../Dataset/' + service + '/time_load_cor_matrix.npy'\n","        train, val, test = create_dataset(data, config['chop_train'], config['chop_val'], config['chop_test'])\n","        dataset = Dataset(train, val, test, config['device'])\n","    \n","        # Maximum of single cluster traffic in the training set (for normalization)\n","        maximum = np.max(train[0])\n","    \n","\n","        # Running many simulations for a given service and alpha\n","        for i in range(1, num_runs+1):\n","\n","            # Initial extremes of the interval of the Minimum Level Threshold tau (expressed as fraction of maximum)\n","            tau_min = 0.0\n","            tau_max = 1.0\n","    \n","            # Current extremes of the interval of tau\n","            c = tau_min\n","            d = tau_max\n","    \n","            # Iterations counter for golden search algorithm\n","            iterations = 1\n","    \n","            # Dictionary collecting denormalized validation loss values for a given tau\n","            val_dict = {}\n","    \n","\n","            # Stopping condition for golden search algorithm\n","            while abs(tau_max - tau_min) > stop_value:\n","        \n","                # Determine current Minimum Level Threshold tau\n","                if (iterations%3) > 0:\n","                    # Try tau as left extreme    \n","                    if (iterations%3) == 1:\n","                        tau = c\n","                    # Try tau as right extreme\n","                    else:\n","                        tau = d\n","        \n","\n","                # Run actual golden search algorithm \n","                else:\n","\n","                    # Determine the new extreme of tau interval\n","                    if f_c < f_d:\n","                        print(\"\\nNew right-extreme of the interval is %f\" % d)\n","                        tau_max = d\n","                    else:\n","                        print(\"\\nNew left-extreme of the interval is %f\" % c)\n","                        tau_min = c\n","                \n","                    print(\"Current length of tau interval is %f \\n\" % abs(tau_max - tau_min))\n","                    c = tau_max - (tau_max - tau_min) / gratio\n","                    d = tau_min + (tau_max - tau_min) / gratio\n","                    iterations = iterations + 1\n","                    continue\n","        \n","\n","                # Compute denormalized validation loss for current tau\n","                f_val = val_dict.get(round(tau,6))\n","                print(\"\\nSearching a threshold in the interval [%f,%f]\" % (tau_min, tau_max))\n","                print(\"Threshold for this run is %f\" % tau)\n","        \n","\n","                # Denormalized validation loss not yet calculated for current tau\n","                if f_val == None:\n","        \n","                    # Dataloader initialization\n","                    dataloader = DataLoader(dataset, batch_size=config['series_batch'], shuffle=False)\n","\n","                    # Model initialization\n","                    run_id = service + '/Alpha_' + str(alpha) + '/Simulation_' + str(i)\n","                    model = TESRNN(tau = tau, maximum = maximum, num_clusters = num_clusters, config = config, run_id = run_id)\n","\n","                    # Run model trainer\n","                    trainer = TESRNNTrainer(model, dataloader, run_id, config)\n","                    trainer.train_epochs()\n","    \n","                    # Run model validator\n","                    validator = TESRNNValidator(model, dataloader, run_id, config)\n","                    validator.validating()\n","        \n","                    # Compute denormalized validation loss\n","                    norm_preds = np.load('Results/' + run_id + '/val_predictions.npy')\n","                    norm_actuals = np.load('Results/' + run_id + '/val_actuals.npy')\n","                    levels = np.load('Results/' + run_id + '/val_levels.npy')\n","                    val_loss = denorm_validation_loss(norm_preds, norm_actuals, levels, alpha)\n","                    print(\"Denormalized validation loss for this run %f\" % val_loss)\n","                    val_dict[round(tau,6)] = val_loss\n","\n","                    # Set denormalized validation loss for interval extreme\n","                    if (iterations%3) == 1:\n","                        f_c = val_loss\n","                    else:\n","                        f_d = val_loss\n","        \n","\n","                # Denormalized validation loss already calculated for current tau\n","                else:\n","                    print(\"Denormalized validation loss for this run %f\" % f_val)\n","                    # Set denormalized validation loss for interval extreme\n","                    if (iterations%3) == 1:\n","                        f_c = f_val\n","                    else:\n","                        f_d = f_val\n","            \n","\n","                # Increase algorithm iterations\n","                iterations = iterations + 1\n","\n","        \n","    \n","            # Get the final optimal Minimum Level Threshold tau\n","            tau = (tau_min + tau_max) / 2\n","            print('\\nFinally chosen threshold = %f\\n' % tau)\n","            np.save('Results/' + run_id + '/optimal_tau.npy', tau)\n","    \n","\n","\n","            # Run the optimized model\n","    \n","            # Dataloader initialization\n","            dataloader = DataLoader(dataset, batch_size=config['series_batch'], shuffle=False)\n","    \n","            # Model initialization\n","            model = TESRNN(tau = tau, maximum = maximum, num_clusters = num_clusters, config = config, run_id = run_id)\n","    \n","            # Run model trainer\n","            trainer = TESRNNTrainer(model, dataloader, run_id, config)\n","            trainer.train_epochs()\n","    \n","            # Run model tester\n","            tester = TESRNNTester(model, dataloader, run_id, config)\n","            tester.testing()"],"metadata":{"id":"FkKJiRG10k0w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649889337752,"user_tz":-120,"elapsed":125349,"user":{"displayName":"Leonardo Lo Schiavo","userId":"03721989530819158623"}},"outputId":"be401e4f-9652-481a-b8f1-c2775474c4cc"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Searching a threshold in the interval [0.000000,1.000000]\n","Threshold for this run is 0.000000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Denormalized validation loss for this run 15666260865819.011719\n","\n","Searching a threshold in the interval [0.000000,1.000000]\n","Threshold for this run is 1.000000\n","Denormalized validation loss for this run 76495348576060.156250\n","\n","New right-extreme of the interval is 1.000000\n","Current length of tau interval is 1.000000 \n","\n","\n","Searching a threshold in the interval [0.000000,1.000000]\n","Threshold for this run is 0.381966\n","Denormalized validation loss for this run 20417304004235.574219\n","\n","Searching a threshold in the interval [0.000000,1.000000]\n","Threshold for this run is 0.618034\n","Denormalized validation loss for this run 29549925739494.519531\n","\n","New right-extreme of the interval is 0.618034\n","Current length of tau interval is 0.618034 \n","\n","\n","Searching a threshold in the interval [0.000000,0.618034]\n","Threshold for this run is 0.236068\n","Denormalized validation loss for this run 17089079405600.777344\n","\n","Searching a threshold in the interval [0.000000,0.618034]\n","Threshold for this run is 0.381966\n","Denormalized validation loss for this run 20417304004235.574219\n","\n","New right-extreme of the interval is 0.381966\n","Current length of tau interval is 0.381966 \n","\n","\n","Searching a threshold in the interval [0.000000,0.381966]\n","Threshold for this run is 0.145898\n","Denormalized validation loss for this run 17068272449882.089844\n","\n","Searching a threshold in the interval [0.000000,0.381966]\n","Threshold for this run is 0.236068\n","Denormalized validation loss for this run 17089079405600.777344\n","\n","New right-extreme of the interval is 0.236068\n","Current length of tau interval is 0.236068 \n","\n","\n","Searching a threshold in the interval [0.000000,0.236068]\n","Threshold for this run is 0.090170\n","Denormalized validation loss for this run 17094285053238.253906\n","\n","Searching a threshold in the interval [0.000000,0.236068]\n","Threshold for this run is 0.145898\n","Denormalized validation loss for this run 17068272449882.089844\n","\n","New left-extreme of the interval is 0.090170\n","Current length of tau interval is 0.145898 \n","\n","\n","Searching a threshold in the interval [0.090170,0.236068]\n","Threshold for this run is 0.145898\n","Denormalized validation loss for this run 17068272449882.089844\n","\n","Searching a threshold in the interval [0.090170,0.236068]\n","Threshold for this run is 0.180340\n","Denormalized validation loss for this run 17539725866459.398438\n","\n","New right-extreme of the interval is 0.180340\n","Current length of tau interval is 0.090170 \n","\n","\n","Searching a threshold in the interval [0.090170,0.180340]\n","Threshold for this run is 0.124612\n","Denormalized validation loss for this run 16402386859083.689453\n","\n","Searching a threshold in the interval [0.090170,0.180340]\n","Threshold for this run is 0.145898\n","Denormalized validation loss for this run 17068272449882.089844\n","\n","New right-extreme of the interval is 0.145898\n","Current length of tau interval is 0.055728 \n","\n","\n","Searching a threshold in the interval [0.090170,0.145898]\n","Threshold for this run is 0.111456\n","Denormalized validation loss for this run 20879398872291.156250\n","\n","Searching a threshold in the interval [0.090170,0.145898]\n","Threshold for this run is 0.124612\n","Denormalized validation loss for this run 16402386859083.689453\n","\n","New left-extreme of the interval is 0.111456\n","Current length of tau interval is 0.034442 \n","\n","\n","Searching a threshold in the interval [0.111456,0.145898]\n","Threshold for this run is 0.124612\n","Denormalized validation loss for this run 16402386859083.689453\n","\n","Searching a threshold in the interval [0.111456,0.145898]\n","Threshold for this run is 0.132742\n","Denormalized validation loss for this run 14250408218264.564453\n","\n","New left-extreme of the interval is 0.124612\n","Current length of tau interval is 0.021286 \n","\n","\n","Searching a threshold in the interval [0.124612,0.145898]\n","Threshold for this run is 0.132742\n","Denormalized validation loss for this run 14250408218264.564453\n","\n","Searching a threshold in the interval [0.124612,0.145898]\n","Threshold for this run is 0.137767\n","Denormalized validation loss for this run 18121585424715.324219\n","\n","New right-extreme of the interval is 0.137767\n","Current length of tau interval is 0.013156 \n","\n","\n","Searching a threshold in the interval [0.124612,0.137767]\n","Threshold for this run is 0.129637\n","Denormalized validation loss for this run 16707673147442.898438\n","\n","Searching a threshold in the interval [0.124612,0.137767]\n","Threshold for this run is 0.132742\n","Denormalized validation loss for this run 14250408218264.564453\n","\n","New left-extreme of the interval is 0.129637\n","Current length of tau interval is 0.008131 \n","\n","\n","Finally chosen threshold = 0.133702\n","\n","\n","Testing model ... \n","Test set (normalized) overprovisioning: 852.562682 \n","Test set SLA violations: 10 \n"]}]}]}